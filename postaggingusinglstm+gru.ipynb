{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMaORQBb0SZd2UgLa68/C8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimrat4/POSTaggingusingLSTM-GRU/blob/main/postaggingusinglstm%2Bgru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from nltk.corpus import treebank\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "DReh54a9xTvp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "\n",
        "sentences = treebank.tagged_sents()\n",
        "train_data, test_data = train_test_split(sentences, test_size=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WyD0FgIxVEt",
        "outputId": "38186d97-bba6-4e41-9e6f-40463c71a655"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = defaultdict(lambda: len(word_to_ix))\n",
        "tag_to_ix = defaultdict(lambda: len(tag_to_ix))\n",
        "\n",
        "word_to_ix[\"<PAD>\"]\n",
        "tag_to_ix[\"<PAD>\"]\n",
        "\n",
        "\n",
        "for sent in train_data:\n",
        "    for word, tag in sent:\n",
        "        word_to_ix[word]\n",
        "        tag_to_ix[tag]\n"
      ],
      "metadata": {
        "id": "Eff93-iKxbfb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = dict(word_to_ix)\n",
        "tag_to_ix = dict(tag_to_ix)\n",
        "ix_to_tag = {v: k for k, v in tag_to_ix.items()}"
      ],
      "metadata": {
        "id": "V83b0ISzyjGq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PosDataset(Dataset):\n",
        "    def __init__(self, data, word_to_ix, tag_to_ix, max_len=50):\n",
        "        self.data = data\n",
        "        self.word_to_ix = word_to_ix\n",
        "\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.data[idx]\n",
        "        words = [self.word_to_ix.get(word, 0) for word, tag in sentence]\n",
        "        tags = [self.tag_to_ix.get(tag, 0) for word, tag in sentence]\n",
        "\n",
        "\n",
        "        while len(words) < self.max_len:\n",
        "            words.append(self.word_to_ix[\"<PAD>\"])\n",
        "            tags.append(self.tag_to_ix[\"<PAD>\"])\n",
        "        return torch.tensor(words[:self.max_len]), torch.tensor(tags[:self.max_len])\n"
      ],
      "metadata": {
        "id": "m5z65jjpxddz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRULSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim=128, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        gru_out, _ = self.gru(embedded)\n",
        "        lstm_out, _ = self.lstm(gru_out)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "mI72hnMHxfiE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "MAX_LEN = 50"
      ],
      "metadata": {
        "id": "1R6FBHbHyuKB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PosDataset(train_data, word_to_ix, tag_to_ix, MAX_LEN)\n",
        "test_dataset = PosDataset(test_data, word_to_ix, tag_to_ix, MAX_LEN)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "lp8GzQsHy9Ku"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRULSTMTagger(len(word_to_ix), len(tag_to_ix))\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tag_to_ix[\"<PAD>\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "pC9pfszvzBb5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "        loss = loss_fn(outputs.view(-1, outputs.shape[-1]), y_batch.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nTui7NoxisO",
        "outputId": "fd6903dc-286b-4915-98b9-3d7ac4cfaa60"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 285.7796\n",
            "Epoch 2 Loss: 161.4240\n",
            "Epoch 3 Loss: 107.1666\n",
            "Epoch 4 Loss: 77.9148\n",
            "Epoch 5 Loss: 59.4022\n",
            "Epoch 6 Loss: 46.6446\n",
            "Epoch 7 Loss: 37.2377\n",
            "Epoch 8 Loss: 30.1681\n",
            "Epoch 9 Loss: 24.6363\n",
            "Epoch 10 Loss: 20.3403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch in test_loader:\n",
        "        outputs = model(x_batch)\n",
        "        preds = torch.argmax(outputs, dim=-1)\n",
        "        mask = y_batch != tag_to_ix[\"<PAD>\"]\n",
        "        correct += (preds[mask] == y_batch[mask]).sum().item()\n",
        "        total += mask.sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snRSmhcVxmWP",
        "outputId": "0717ead6-969e-4a59-9e4b-e47cbcf2cc0f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 88.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_sent = random.choice(test_data)\n",
        "print(\"Original sentence with gold tags:\")\n",
        "print(random_sent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3mCQbFdzKel",
        "outputId": "65641060-ecef-466f-df3c-55dba85fc12c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence with gold tags:\n",
            "[('While', 'IN'), ('the', 'DT'), ('small', 'JJ'), ('deals', 'NNS'), ('are', 'VBP'), ('far', 'RB'), ('less', 'RBR'), ('conspicuous', 'JJ'), (',', ','), ('they', 'PRP'), ('add', 'VBP'), ('to', 'TO'), ('Japanese', 'JJ'), ('penetration', 'NN'), ('of', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('market', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_only = [word for word, tag in random_sent]\n",
        "def predict_on_tokens(words):\n",
        "    model.eval()\n",
        "    word_ids = [word_to_ix.get(w, 0) for w in words]\n",
        "    while len(word_ids) < MAX_LEN:\n",
        "        word_ids.append(word_to_ix[\"<PAD>\"])\n",
        "    input_tensor = torch.tensor([word_ids])\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "    preds = torch.argmax(outputs, dim=-1)[0]\n",
        "    tags = [ix_to_tag[p.item()] for p in preds[:len(words)]]\n",
        "    return list(zip(words, tags))\n",
        "\n",
        "predicted = predict_on_tokens(words_only)\n",
        "\n",
        "print(\"\\nPredicted POS Tags:\")\n",
        "print(predicted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L03bEkhLxr8A",
        "outputId": "f0668e2a-8745-452c-d9ed-2eb8c85f94dc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted POS Tags:\n",
            "[('While', 'IN'), ('the', 'DT'), ('small', 'JJ'), ('deals', 'NNS'), ('are', 'VBP'), ('far', 'RB'), ('less', 'JJR'), ('conspicuous', 'JJ'), (',', ','), ('they', 'PRP'), ('add', 'VBP'), ('to', 'TO'), ('Japanese', 'JJ'), ('penetration', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('U.S.', 'NNP'), ('market', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}